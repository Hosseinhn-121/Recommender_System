{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Spark\n",
    "!wget -q https://dlcdn.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the file\n",
    "!tar xf spark-3.4.0-bin-hadoop3.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = '/content/spark-3.4.0-bin-hadoop3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install library for finding Spark\n",
    "!pip install -q findspark\n",
    "# Import the libary\n",
    "import findspark\n",
    "# Initiate findspark\n",
    "findspark.init()\n",
    "# Check the location for Spark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "import pyspark as ps\n",
    "from pyspark.sql import SparkSession\n",
    "# Create a Spark Session\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "# Check Spark Session Information\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import udf, col, when\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "from scipy.sparse import load_npz\n",
    "import pandas as pd\n",
    "\n",
    "spark = ps.sql.SparkSession.builder.master(\"local\").appName(\"recom\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "test_csr=load_npz('/content/drive/MyDrive/recom/train_csr.npz')\n",
    "# train_csr = load_npz('/content/drive/MyDrive/recom/train_csr.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = test_csr.nonzero()\n",
    "df2 = pd.DataFrame(columns=[ 'user_id', 'movie_id','rating'])\n",
    "df2['user_id'] = cols\n",
    "df2['movie_id'] = rows\n",
    "df2['rating'] = test_csr.data\n",
    "df2.to_csv('df_s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "schema = StructType([\n",
    "    StructField(\"index_\", IntegerType(), True),\n",
    "    StructField(\"movie_id\", IntegerType(), True),\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"rank\", IntegerType(), True)])\n",
    "ratings= spark.read.csv('/content/drive/MyDrive/recom/df_s.csv', sep='\\t', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training , validation= ratings.randomSplit([.8,.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 4\n",
    "iterat = 20 \n",
    "regparam=0.1\n",
    "errors=[]\n",
    "err=0\n",
    "als=ALS(maxIter=iterat,\n",
    "        regParam=regparam,\n",
    "        rank=rank,\n",
    "        userCol=\"user_id\",\n",
    "        itemCol=\"movie_id\",\n",
    "        ratingCol=\"rank\",\n",
    "        coldStartStrategy=\"drop\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions = predictions.filter(col('prediction') != np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\",labelCol=\"rank\",predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(new_predictions)\n",
    "print(\"RMSE=\"+str(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
